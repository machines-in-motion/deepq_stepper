{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.74639275] 2.42\n",
      "[ 0.         -0.57488137] 2.52\n",
      "[0.         0.67397237] 2.28\n",
      "[0.         6.43179174] 120.7\n"
     ]
    }
   ],
   "source": [
    "# This code tests the trained 3d dq stepper\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#for live plotting\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%run cent_env.ipynb #imports LIPM Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lipm - 8 layers , 512 each\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, inp_size, out_size):\n",
    "        \n",
    "        super(NN, self).__init__()\n",
    "        self.l1 = nn.Linear(inp_size, 512)\n",
    "        self.l2 = nn.Linear(512, 512)\n",
    "        self.l3 = nn.Linear(512, 512)\n",
    "        self.l4 = nn.Linear(512, 512)\n",
    "        self.l5 = nn.Linear(512, 512)\n",
    "        self.l6 = nn.Linear(512, 512)\n",
    "        self.l7 = nn.Linear(512, 512)\n",
    "        self.l8 = nn.Linear(512, 512)\n",
    "        self.l9 = nn.Linear(512, out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        x = F.relu(self.l5(x))\n",
    "        x = F.relu(self.l6(x))\n",
    "        x = F.relu(self.l7(x))\n",
    "        x = F.relu(self.l8(x))\n",
    "        x = self.l9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQStepper:\n",
    "    def __init__(self, env, lr = 1e-4, gamma = 0.9, use_tarnet = False, trained_model = None):\n",
    "        '''\n",
    "        This is a 3d dq stepper.\n",
    "        State = [x-ux, y-uy, z-uz, xd, yd, n, action_x, action_y, action_z]\n",
    "        '''\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.dq_stepper = NN(11, 1).to(self.device) #state+ action -> q_value\n",
    "        if trained_model:\n",
    "            self.dq_stepper.load_state_dict(torch.load(trained_model))\n",
    "            self.dq_stepper.eval()\n",
    "        self.optimizer = torch.optim.SGD(self.dq_stepper.parameters(), lr)\n",
    "        self.use_tarnet = use_tarnet\n",
    "        if self.use_tarnet:\n",
    "            self.dq_tar_stepper = NN(11, 1).to(self.device)\n",
    "            self.dq_tar_stepper.load_state_dict(self.dq_stepper.state_dict())\n",
    "            self.dq_tar_stepper.eval()\n",
    "        self.gamma = gamma #discount factor\n",
    "        self.no_actions = env.no_actions\n",
    "        \n",
    "        # This is the template of x_in that goes into the dq stepper\n",
    "        self.max_step_height = 0.00\n",
    "        self.max_no = 5 #number of actions with non zero step in z\n",
    "        self.x_in = np.zeros((self.no_actions[0]*self.no_actions[1], 11))\n",
    "        self.x_in[:,8] = np.tile(np.arange(self.no_actions[0]), self.no_actions[1])\n",
    "        self.x_in[:,9] = np.repeat(np.arange(self.no_actions[1]), self.no_actions[0])\n",
    "        \n",
    "    def predict_action_value(self, x):\n",
    "        # this function predicts the q_value for different actions and returns action and min q value\n",
    "        self.x_in[:,[0, 1, 2, 3, 4, 5, 6, 7]] = x\n",
    "        for e in np.random.randint(0, len(self.x_in), self.max_no):\n",
    "            self.x_in[e, 10] = 2*self.max_step_height*(np.random.rand() - 0.5)\n",
    "        torch_x_in = torch.FloatTensor(self.x_in, device = self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.dq_stepper(torch_x_in).detach().numpy()\n",
    "            action_index = np.argmin(q_values)\n",
    "            action_x = int(action_index%self.no_actions[0])\n",
    "            action_y = int(action_index//self.no_actions[0])\n",
    "            action_z = self.x_in[action_index,10]\n",
    "        return [action_x, action_y, action_z], q_values[action_index]\n",
    "    \n",
    "    def tar_predict_action_value(self, x):\n",
    "        # this function uses tar net to predict \n",
    "        # the q_value for different actions and returns action and min q value\n",
    "        self.x_in[:,[0, 1, 2, 3, 4, 5, 6, 7]] = x\n",
    "        for e in np.random.randint(0, len(self.x_in), self.max_no):\n",
    "            self.x_in[e, 10] = 2*self.max_step_height*(np.random.rand() - 0.5)\n",
    "        torch_x_in = torch.FloatTensor(self.x_in, device = self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.dq_tar_stepper(torch_x_in).detach().numpy()\n",
    "            action_index = np.argmin(q_values)\n",
    "            action_x = int(action_index%self.no_actions[0])\n",
    "            action_y = int(action_index//self.no_actions[0])\n",
    "            action_z = self.x_in[action_index,10]\n",
    "        return [action_x, action_y, action_z], q_values[action_index]\n",
    "    \n",
    "    def predict_eps_greedy(self, x, eps = 0.1):\n",
    "        # This function returns prediction based on epsillon greedy algorithm\n",
    "        if np.random.random() > eps:\n",
    "            return self.predict_action_value(x)[0]\n",
    "        else:\n",
    "            action_x = np.random.randint(self.no_actions[0])\n",
    "            action_y = np.random.randint(self.no_actions[1])\n",
    "            action_z = 2*self.max_step_height*(np.random.rand() - 0.5)\n",
    "            \n",
    "        return [action_x, action_y, action_z]\n",
    "        \n",
    "    def optimize(self, mini_batch, tau = 0.001):\n",
    "        # This function performs one step of back propogation for the given mini_batch data\n",
    "        x_in = torch.FloatTensor(mini_batch[:,0:11].copy(), device = self.device)\n",
    "        y_train = torch.FloatTensor(mini_batch[:,11].copy(), device = self.device)\n",
    "        for i in range(len(mini_batch)):\n",
    "            if not np.isnan(mini_batch[i,12:]).all():\n",
    "                if not self.use_tarnet:\n",
    "                    y_train[i] += self.gamma * self.predict_action_value(mini_batch[i,12:])[1]\n",
    "                else:\n",
    "                    y_train[i] += self.gamma * self.tar_predict_action_value(mini_batch[i,12:])[1]\n",
    "\n",
    "        y_train = y_train.unsqueeze(1).detach() #ensures that gradients are not computed on this\n",
    "        x_train = self.dq_stepper(x_in)\n",
    "\n",
    "        loss = F.mse_loss(x_train, y_train)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        if self.use_tarnet:\n",
    "            for tar_param, param in zip(self.dq_tar_stepper.parameters(), self.dq_stepper.parameters()):\n",
    "                tar_param.data.copy_(tar_param.data * (1.0 - tau) + param.data * tau)\n",
    "                \n",
    "        return loss\n",
    "    \n",
    "    def live_plot(self, history, e, figsize=(15,25), window = 500, title='history'):\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(3, 1, figsize=figsize)\n",
    "        ax[0].plot(history['epi_cost'], label='epi_cost', color = 'orange')\n",
    "        ax[0].grid(True)\n",
    "        ax[0].legend() # the plot evolves to the right\n",
    "        if e > window:\n",
    "            ax[1].plot(np.arange(e-window+1, e), history['epi_cost'][e-window:], label='epi_cost zoom')\n",
    "            ax[1].grid(True)\n",
    "            ax[1].legend() # the plot evolves to the right\n",
    "        ax[2].plot(history['loss'], label='loss', color = 'black')\n",
    "        ax[2].grid(True)\n",
    "        ax[2].legend() # the plot evolves to the right\n",
    "        ax[2].set_ylim(0, 60)\n",
    "        plt.xlabel('episode')\n",
    "        plt.show();\n",
    "        \n",
    "    def predict_q(self, x, terrain):\n",
    "        #for debugging\n",
    "        # this function predicts the q_value for different actions and returns action and min q value\n",
    "        self.x_in[:,[0, 1, 2, 3, 4, 5, 6, 7]] = x\n",
    "        self.x_in[:,10] = terrain\n",
    "        torch_x_in = torch.FloatTensor(self.x_in, device = self.device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.dq_stepper(torch_x_in).detach().numpy()\n",
    "            action_index = np.argmin(q_values)\n",
    "            action_x = int(action_index%self.no_actions[0])\n",
    "            action_y = int(action_index//self.no_actions[0])\n",
    "            action_z = self.x_in[action_index,10]\n",
    "            \n",
    "        return q_values, [action_x, action_y, action_z] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.04 0.09 0.13 0.18 0.26 0.37 0.52 0.73]\n"
     ]
    }
   ],
   "source": [
    "ht = 0.28\n",
    "step_time = 0.1\n",
    "air_time = 0.1\n",
    "env = CentEnv(ht, 0.13, 0.6, [1.0, 3.5, 0.5], [1,9])\n",
    "print(env.action_space_y)\n",
    "dqs = DQStepper(env, lr=1e-4, gamma=0.98, use_tarnet= True, trained_model='../../models/dqs_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[0, 4, 0.0] 0.39 False [0. 0.]\n",
      "[0, 2, 0.0] 0.11 False [0.         0.09648857]\n",
      "[0, 2, 0.0] 0.25 False [0.         0.01564153]\n",
      "[0, 1, 0.0] 0.16 False [0.         0.05362258]\n",
      "[0, 1, 0.0] 0.43 False [ 0.         -0.01523672]\n",
      "[0, 3, 0.0] 0.4 False [ 0.         -0.09982851]\n",
      "[0, 1, 0.0] 0.21 False [ 0.         -0.10367108]\n",
      "[0, 0, 0.0] 0.21 False [0.         0.02912016]\n",
      "[0, 1, 0.0] 0.41 False [0.         0.02234669]\n",
      "[0, 3, 0.0] 0.4 False [ 0.         -0.09459664]\n",
      "showing episode...\n"
     ]
    }
   ],
   "source": [
    "no_steps = 10 ## number of steps simulated per episode (pendulum steps)\n",
    "\n",
    "v_des = [0.0, 0]\n",
    "# v_init = [0.0*(np.random.rand() - 0.5), 2.*(np.random.rand() - 0.5)]\n",
    "v_init = [.0, 0.0]\n",
    "print(v_init)\n",
    "state = env.reset_env([0.0, 0.0, ht, v_init[0], v_init[1], 0.0], v_des, no_steps*(2*step_time + air_time))\n",
    "epi_cost = 0\n",
    "for n in range(no_steps):\n",
    "    terrain = 0.00\n",
    "    action = dqs.predict_q(state, terrain)[1]\n",
    "    next_state, cost, done = env.step_env(action, step_time, air_time)\n",
    "    print(action, cost, done, state[3:5])\n",
    "    epi_cost += cost\n",
    "    state = next_state\n",
    "    if done:\n",
    "        print(epi_cost)\n",
    "        break\n",
    "print(\"showing episode...\")\n",
    "# env.show_episode(5)\n",
    "# env.show_episode_side(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9a445d4ba8>]"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(env.sim_data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.04 0.09 0.13 0.18 0.26 0.37 0.52 0.73]\n"
     ]
    }
   ],
   "source": [
    "ht = 0.3\n",
    "step_time = 0.1\n",
    "air_time = 0.1\n",
    "env_main = CentEnv(ht, 0.13, 0.5, [0.5, 3.0, 1.5], [11,9])\n",
    "env_x = CentEnv(ht, 0., 0.5, [0.5, 3.0, 1.5], [11,1])\n",
    "dqs_x = DQStepper(env_x, lr=1e-4, gamma=0.98, use_tarnet= True, trained_model='../../models/dqs_1_str')\n",
    "env_y = CentEnv(ht, 0.13, 0.6, [0.5, 3.0, 1.5], [1,9])\n",
    "dqs_y = DQStepper(env_y, lr=1e-4, gamma=0.98, use_tarnet= True, trained_model='../../models/dqs_1')\n",
    "print(env_y.action_space_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9575987516862537, -0.3306849199252061]\n",
      "[9 1 0] 2.52 False [ 0.          0.065       0.3         0.95759875 -0.33068492]\n",
      "[5 2 0] 1.13 False [-0.10215502 -0.01017055  0.29996423  0.48230179 -0.08756689]\n",
      "[2 4 0] 2.25 False [-0.08096681  0.04466866  0.29992299 -0.29291545  0.04528383]\n",
      "[4 5 0] 1.95 False [ 0.02673282 -0.07592104  0.29992418 -0.51091901 -0.05740284]\n",
      "[4 3 0] 2.31 False [-0.00953466  0.05997378  0.29992415 -0.39539793 -0.14609368]\n",
      "[1 4 0] 2.75 False [-0.05942506 -0.05122655  0.29992415 -0.63073122 -0.07606111]\n",
      "[4 3 0] 0.9 False [ 0.06975422  0.04719444  0.29992415 -0.5691521  -0.10756921]\n",
      "[7 5 0] 2.63 False [ 0.07969575 -0.06963777  0.29992415  0.07043358 -0.16415044]\n",
      "[7 0 0] 1.56 False [ 0.00119227  0.03554314  0.29992415  0.40583736 -0.31078731]\n",
      "[4 4 0] 1.78 False [-0.07425229 -0.02644674  0.29992415  0.09863078 -0.23740331]\n",
      "showing episode...\n"
     ]
    }
   ],
   "source": [
    "no_steps = 10 ## number of steps simulated per episode (pendulum steps)\n",
    "\n",
    "v_des = [0., 0]\n",
    "v_init = [3.0*(np.random.rand() - 0.5), 1.0*(np.random.rand() - 0.5)]\n",
    "# v_init = [0.5, 0.0]\n",
    "print(v_init)\n",
    "state = env_main.reset_env([0.0, 0.0, ht, v_init[0], v_init[1], 0.0], v_des, no_steps*(2*step_time + air_time))\n",
    "epi_cost = 0\n",
    "for n in range(no_steps):\n",
    "    terrain = 0.00\n",
    "    # for x axis\n",
    "    state_x = state.copy()\n",
    "    state_x[1] = 0.0\n",
    "    state_x[4] = 0.0\n",
    "    action_x = dqs_x.predict_q(state_x, terrain)[1] \n",
    "    # for y axis\n",
    "    state_y = state.copy()\n",
    "    state_y[0] = 0.0\n",
    "    state_y[3] = 0.0\n",
    "    action_y = dqs_y.predict_q(state_y, terrain)[1] \n",
    "    action = np.array([int(action_x[0]), int(action_y[1]), 0])\n",
    "\n",
    "    next_state, cost, done = env_main.step_env(action, step_time, air_time)\n",
    "    print(action, cost, done, state[0:5])\n",
    "    epi_cost += cost\n",
    "    state = next_state\n",
    "    if done:\n",
    "        print(epi_cost)\n",
    "        break\n",
    "print(\"showing episode...\")\n",
    "# env_main.show_episode(5)\n",
    "# env_main.show_episode_side(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
